{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f76adef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2019e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    transform=transforms.ToTensor(),\n",
    "    download=True\n",
    ")\n",
    "\n",
    "val_dataset = torchvision.datasets.MNIST(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    transform=transforms.ToTensor(),\n",
    "    download=True\n",
    ")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=64,\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "966d846f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def one_hot(labels, num_classes=10):\n",
    "    oh = np.zeros((labels.size, num_classes))\n",
    "    oh[np.arange(labels.size), labels] = 1\n",
    "    return oh\n",
    "\n",
    "def softmax(z):\n",
    "    z = z - np.max(z, axis=1, keepdims=True)\n",
    "    exp_z = np.exp(z)\n",
    "    return exp_z / np.sum(exp_z, axis=1, keepdims=True)\n",
    "\n",
    "def relu(z):\n",
    "    return np.maximum(0, z)\n",
    "\n",
    "def relu_derivative(z):\n",
    "    return (z > 0).astype(float)\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def sigmoid_derivative(z):\n",
    "    s = sigmoid(z)\n",
    "    return s * (1 - s)\n",
    "\n",
    "def tanh(z):\n",
    "    return np.tanh(z)\n",
    "\n",
    "def tanh_derivative(z):\n",
    "    return 1 - np.tanh(z)**2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38d9c444",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, layer_sizes, activation='relu', lr=0.01):\n",
    "        self.layer_sizes = layer_sizes\n",
    "        self.activation_name = activation\n",
    "        self.lr = lr\n",
    "        \n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "        self.Z = []\n",
    "        self.A = []\n",
    "        \n",
    "        for i in range(len(layer_sizes) - 1):\n",
    "            w = np.random.randn(layer_sizes[i], layer_sizes[i+1]) * np.sqrt(2 / layer_sizes[i])\n",
    "            b = np.zeros((1, layer_sizes[i+1]))\n",
    "            self.weights.append(w)\n",
    "            self.biases.append(b)\n",
    "\n",
    "    def activation(self, z):\n",
    "        if self.activation_name == 'relu':\n",
    "            return relu(z)\n",
    "        elif self.activation_name == 'sigmoid':\n",
    "            return sigmoid(z)\n",
    "        elif self.activation_name == 'tanh':\n",
    "            return tanh(z)\n",
    "\n",
    "    def activation_derivative(self, z):\n",
    "        if self.activation_name == 'relu':\n",
    "            return relu_derivative(z)\n",
    "        elif self.activation_name == 'sigmoid':\n",
    "            return sigmoid_derivative(z)\n",
    "        elif self.activation_name == 'tanh':\n",
    "            return tanh_derivative(z)\n",
    "\n",
    "    def forward(self, X):\n",
    "        self.A = [X]\n",
    "        self.Z = []\n",
    "        \n",
    "        for i in range(len(self.weights) - 1):\n",
    "            z = self.A[-1] @ self.weights[i] + self.biases[i]\n",
    "            a = self.activation(z)\n",
    "            self.Z.append(z)\n",
    "            self.A.append(a)\n",
    "        \n",
    "        z = self.A[-1] @ self.weights[-1] + self.biases[-1]\n",
    "        a = softmax(z)\n",
    "        self.Z.append(z)\n",
    "        self.A.append(a)\n",
    "        return a\n",
    "\n",
    "    def compute_loss(self, y_true, y_pred):\n",
    "        m = y_true.shape[0]\n",
    "        return -np.sum(y_true * np.log(y_pred + 1e-9)) / m\n",
    "\n",
    "    def backward(self, y_true):\n",
    "        m = y_true.shape[0]\n",
    "        dZ = self.A[-1] - y_true\n",
    "        self.dW = []\n",
    "        self.db = []\n",
    "        \n",
    "        for i in reversed(range(len(self.weights))):\n",
    "            dW = self.A[i].T @ dZ / m\n",
    "            db = np.sum(dZ, axis=0, keepdims=True) / m\n",
    "            self.dW.insert(0, dW)\n",
    "            self.db.insert(0, db)\n",
    "            if i != 0:\n",
    "                dZ = (dZ @ self.weights[i].T) * self.activation_derivative(self.Z[i-1])\n",
    "\n",
    "    def update_parameters(self):\n",
    "        for i in range(len(self.weights)):\n",
    "            self.weights[i] -= self.lr * self.dW[i]\n",
    "            self.biases[i] -= self.lr * self.db[i]\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.argmax(self.forward(X), axis=1)\n",
    "\n",
    "    def evaluate(self, loader):\n",
    "        total_loss, correct, total = 0, 0, 0\n",
    "        for images, labels in loader:\n",
    "            images = images.cpu().numpy().reshape(images.size(0), -1) / 255.0\n",
    "            labels = labels.cpu().numpy()\n",
    "            y = one_hot(labels)\n",
    "            preds = self.forward(images)\n",
    "            total_loss += self.compute_loss(y, preds) * images.shape[0]\n",
    "            correct += np.sum(np.argmax(preds, axis=1) == labels)\n",
    "            total += images.shape[0]\n",
    "        return total_loss / total, correct / total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24b6e688",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_model(model, train_loader, val_loader, epochs):\n",
    "    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        total_loss, correct, total = 0, 0, 0\n",
    "        \n",
    "        for images, labels in train_loader:\n",
    "            images = images.cpu().numpy().reshape(images.size(0), -1) / 255.0\n",
    "            labels = labels.cpu().numpy()\n",
    "            y = one_hot(labels)\n",
    "            \n",
    "            preds = model.forward(images)\n",
    "            loss = model.compute_loss(y, preds)\n",
    "            \n",
    "            model.backward(y)\n",
    "            model.update_parameters()\n",
    "            \n",
    "            total_loss += loss * images.shape[0]\n",
    "            correct += np.sum(np.argmax(preds, axis=1) == labels)\n",
    "            total += images.shape[0]\n",
    "        \n",
    "        train_loss = total_loss / total\n",
    "        train_acc = correct / total\n",
    "        val_loss, val_acc = model.evaluate(val_loader)\n",
    "        \n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}: Train Acc={train_acc:.4f}, Val Acc={val_acc:.4f}\")\n",
    "    \n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35d30d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running {'layers': [784, 128, 10], 'activation': 'relu'}\n",
      "Epoch 1: Train Acc=0.1183, Val Acc=0.1135\n",
      "Epoch 2: Train Acc=0.1124, Val Acc=0.1135\n",
      "Epoch 3: Train Acc=0.1124, Val Acc=0.1135\n",
      "Epoch 4: Train Acc=0.1124, Val Acc=0.1135\n",
      "Epoch 5: Train Acc=0.1124, Val Acc=0.1135\n",
      "\n",
      "Running {'layers': [784, 256, 128, 10], 'activation': 'relu'}\n",
      "Epoch 1: Train Acc=0.1216, Val Acc=0.1135\n",
      "Epoch 2: Train Acc=0.1124, Val Acc=0.1135\n",
      "Epoch 3: Train Acc=0.1124, Val Acc=0.1135\n",
      "Epoch 4: Train Acc=0.1124, Val Acc=0.1135\n",
      "Epoch 5: Train Acc=0.1124, Val Acc=0.1135\n",
      "\n",
      "Running {'layers': [784, 128, 10], 'activation': 'sigmoid'}\n",
      "Epoch 1: Train Acc=0.1087, Val Acc=0.1135\n",
      "Epoch 2: Train Acc=0.1101, Val Acc=0.1135\n",
      "Epoch 3: Train Acc=0.1092, Val Acc=0.1135\n",
      "Epoch 4: Train Acc=0.1118, Val Acc=0.0892\n",
      "Epoch 5: Train Acc=0.1119, Val Acc=0.1135\n",
      "\n",
      "Running {'layers': [784, 128, 10], 'activation': 'tanh'}\n",
      "Epoch 1: Train Acc=0.1156, Val Acc=0.1135\n",
      "Epoch 2: Train Acc=0.1124, Val Acc=0.1135\n",
      "Epoch 3: Train Acc=0.1124, Val Acc=0.1135\n",
      "Epoch 4: Train Acc=0.1124, Val Acc=0.1135\n",
      "Epoch 5: Train Acc=0.1124, Val Acc=0.1135\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "experiments = [\n",
    "    {'layers': [784, 128, 10], 'activation': 'relu'},\n",
    "    {'layers': [784, 256, 128, 10], 'activation': 'relu'},\n",
    "    {'layers': [784, 128, 10], 'activation': 'sigmoid'},\n",
    "    {'layers': [784, 128, 10], 'activation': 'tanh'},\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "for exp in experiments:\n",
    "    print(\"\\nRunning\", exp)\n",
    "    model = NeuralNetwork(exp['layers'], activation=exp['activation'], lr=0.01)\n",
    "    hist = train_model(model, train_loader, val_loader, epochs=5)\n",
    "    results.append((exp, hist))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68af68d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for i, (cfg, hist) in enumerate(results):\n",
    "    plt.figure()\n",
    "    plt.plot(hist['train_loss'], label='Train Loss')\n",
    "    plt.plot(hist['val_loss'], label='Val Loss')\n",
    "    plt.legend()\n",
    "    plt.title(str(cfg))\n",
    "    plt.savefig(f'exp_{i}_loss.png')\n",
    "    plt.close()\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(hist['train_acc'], label='Train Acc')\n",
    "    plt.plot(hist['val_acc'], label='Val Acc')\n",
    "    plt.legend()\n",
    "    plt.title(str(cfg))\n",
    "    plt.savefig(f'exp_{i}_acc.png')\n",
    "    plt.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
