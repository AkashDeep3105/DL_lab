{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":14849631,"sourceType":"datasetVersion","datasetId":9498065}],"dockerImageVersionId":31259,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"IMPORT","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport numpy as np\nimport random\nfrom collections import Counter\nfrom tqdm import tqdm\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-02-15T16:27:31.220896Z","iopub.execute_input":"2026-02-15T16:27:31.221189Z","iopub.status.idle":"2026-02-15T16:27:31.225804Z","shell.execute_reply.started":"2026-02-15T16:27:31.221169Z","shell.execute_reply":"2026-02-15T16:27:31.224852Z"}},"outputs":[],"execution_count":33},{"cell_type":"markdown","source":"LOADING DATASET","metadata":{}},{"cell_type":"code","source":"with open(\"/kaggle/input/datasets/akashdeep31/poems-100/poems-100.csv\", \"r\", encoding=\"utf-8\") as f:\n    text = f.read().lower()\n\nprint(text[:500])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-15T16:27:31.228340Z","iopub.execute_input":"2026-02-15T16:27:31.228592Z","iopub.status.idle":"2026-02-15T16:27:31.246347Z","shell.execute_reply.started":"2026-02-15T16:27:31.228573Z","shell.execute_reply":"2026-02-15T16:27:31.244955Z"}},"outputs":[{"name":"stdout","text":"text\n\"o my luve's like a red, red rose\nthat’s newly sprung in june;\no my luve's like the melodie\nthat’s sweetly play'd in tune.\n\nas fair art thou, my bonnie lass,\nso deep in luve am i:\nand i will luve thee still, my dear,\ntill a’ the seas gang dry:\n\ntill a’ the seas gang dry, my dear,\nand the rocks melt wi’ the sun:\ni will luve thee still, my dear,\nwhile the sands o’ life shall run.\n\nand fare thee well, my only luve\nand fare thee well, a while!\nand i will come again, my luve,\ntho’ it were ten th\n","output_type":"stream"}],"execution_count":34},{"cell_type":"markdown","source":"PREPROCESSING","metadata":{}},{"cell_type":"code","source":"tokens = text.split()\nprint(\"Total tokens:\", len(tokens))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-15T16:27:31.247715Z","iopub.execute_input":"2026-02-15T16:27:31.247925Z","iopub.status.idle":"2026-02-15T16:27:31.253983Z","shell.execute_reply.started":"2026-02-15T16:27:31.247907Z","shell.execute_reply":"2026-02-15T16:27:31.253218Z"}},"outputs":[{"name":"stdout","text":"Total tokens: 24801\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"vocab = sorted(set(tokens))\nvocab_size = len(vocab)\n\nword_to_idx = {word:i for i,word in enumerate(vocab)}\nidx_to_word = {i:word for word,i in word_to_idx.items()}\n\nprint(\"Vocabulary size:\", vocab_size)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-15T16:27:31.254834Z","iopub.execute_input":"2026-02-15T16:27:31.255057Z","iopub.status.idle":"2026-02-15T16:27:31.272980Z","shell.execute_reply.started":"2026-02-15T16:27:31.255033Z","shell.execute_reply":"2026-02-15T16:27:31.272256Z"}},"outputs":[{"name":"stdout","text":"Vocabulary size: 7045\n","output_type":"stream"}],"execution_count":36},{"cell_type":"code","source":"seq_length = 5\nsequences = []\n\nfor i in range(len(tokens) - seq_length):\n    seq = tokens[i:i+seq_length]\n    target = tokens[i+seq_length]\n    sequences.append((seq, target))\n\nprint(\"Total sequences:\", len(sequences))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-15T16:27:31.274283Z","iopub.execute_input":"2026-02-15T16:27:31.274722Z","iopub.status.idle":"2026-02-15T16:27:31.442301Z","shell.execute_reply.started":"2026-02-15T16:27:31.274702Z","shell.execute_reply":"2026-02-15T16:27:31.441442Z"}},"outputs":[{"name":"stdout","text":"Total sequences: 24796\n","output_type":"stream"}],"execution_count":37},{"cell_type":"markdown","source":"ONE HOT ENCODING","metadata":{}},{"cell_type":"code","source":"def one_hot_encode(word_idx, vocab_size):\n    vec = torch.zeros(vocab_size)\n    vec[word_idx] = 1\n    return vec\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-15T16:27:31.443451Z","iopub.execute_input":"2026-02-15T16:27:31.443680Z","iopub.status.idle":"2026-02-15T16:27:31.455269Z","shell.execute_reply.started":"2026-02-15T16:27:31.443663Z","shell.execute_reply":"2026-02-15T16:27:31.454529Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"X_onehot = []\ny_onehot = []\n\nfor seq, target in sequences:\n    seq_vec = [one_hot_encode(word_to_idx[w], vocab_size) for w in seq]\n    X_onehot.append(torch.stack(seq_vec))\n    y_onehot.append(word_to_idx[target])\n\nX_onehot = torch.stack(X_onehot)\ny_onehot = torch.tensor(y_onehot)\n\nX_onehot = X_onehot.to(device)\ny_onehot = y_onehot.to(device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-15T16:27:31.456171Z","iopub.execute_input":"2026-02-15T16:27:31.456451Z","iopub.status.idle":"2026-02-15T16:27:34.103761Z","shell.execute_reply.started":"2026-02-15T16:27:31.456430Z","shell.execute_reply":"2026-02-15T16:27:34.103103Z"}},"outputs":[],"execution_count":39},{"cell_type":"markdown","source":"RNN Model","metadata":{}},{"cell_type":"code","source":"class RNN_OneHot(nn.Module):\n    def __init__(self, vocab_size, hidden_size):\n        super().__init__()\n        self.rnn = nn.RNN(vocab_size, hidden_size, batch_first=True)\n        self.fc = nn.Linear(hidden_size, vocab_size)\n\n    def forward(self, x):\n        out, _ = self.rnn(x)\n        out = self.fc(out[:, -1, :])\n        return out\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-15T16:27:34.105250Z","iopub.execute_input":"2026-02-15T16:27:34.105560Z","iopub.status.idle":"2026-02-15T16:27:34.110756Z","shell.execute_reply.started":"2026-02-15T16:27:34.105542Z","shell.execute_reply":"2026-02-15T16:27:34.109716Z"}},"outputs":[],"execution_count":40},{"cell_type":"markdown","source":"LSTM Model","metadata":{}},{"cell_type":"code","source":"class LSTM_OneHot(nn.Module):\n    def __init__(self, vocab_size, hidden_size):\n        super().__init__()\n        self.lstm = nn.LSTM(vocab_size, hidden_size, batch_first=True)\n        self.fc = nn.Linear(hidden_size, vocab_size)\n\n    def forward(self, x):\n        out, _ = self.lstm(x)\n        out = self.fc(out[:, -1, :])\n        return out\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-15T16:27:34.111770Z","iopub.execute_input":"2026-02-15T16:27:34.111984Z","iopub.status.idle":"2026-02-15T16:27:34.126712Z","shell.execute_reply.started":"2026-02-15T16:27:34.111965Z","shell.execute_reply":"2026-02-15T16:27:34.125965Z"}},"outputs":[],"execution_count":41},{"cell_type":"markdown","source":"Training","metadata":{}},{"cell_type":"code","source":"def train_model(model, X, y, epochs=10):\n    model.to(device)\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n    criterion = nn.CrossEntropyLoss()\n\n    for epoch in range(epochs):\n        optimizer.zero_grad()\n        output = model(X)\n        loss = criterion(output, y)\n        loss.backward()\n        optimizer.step()\n\n        print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-15T16:27:34.128575Z","iopub.execute_input":"2026-02-15T16:27:34.128835Z","iopub.status.idle":"2026-02-15T16:27:34.141332Z","shell.execute_reply.started":"2026-02-15T16:27:34.128785Z","shell.execute_reply":"2026-02-15T16:27:34.140453Z"}},"outputs":[],"execution_count":42},{"cell_type":"code","source":"model_onehot_RNN = RNN_OneHot(vocab_size, 256)\ntrain_model(model_onehot, X_onehot, y_onehot, epochs=40)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-15T16:27:34.142301Z","iopub.execute_input":"2026-02-15T16:27:34.142626Z","iopub.status.idle":"2026-02-15T16:41:39.343519Z","shell.execute_reply.started":"2026-02-15T16:27:34.142604Z","shell.execute_reply":"2026-02-15T16:41:39.342796Z"}},"outputs":[{"name":"stdout","text":"Epoch 1, Loss: 7.8987\nEpoch 2, Loss: 7.7698\nEpoch 3, Loss: 7.6390\nEpoch 4, Loss: 7.5126\nEpoch 5, Loss: 7.3973\nEpoch 6, Loss: 7.2989\nEpoch 7, Loss: 7.2201\nEpoch 8, Loss: 7.1601\nEpoch 9, Loss: 7.1149\nEpoch 10, Loss: 7.0797\nEpoch 11, Loss: 7.0501\nEpoch 12, Loss: 7.0234\nEpoch 13, Loss: 6.9983\nEpoch 14, Loss: 6.9741\nEpoch 15, Loss: 6.9509\nEpoch 16, Loss: 6.9289\nEpoch 17, Loss: 6.9083\nEpoch 18, Loss: 6.8896\nEpoch 19, Loss: 6.8734\nEpoch 20, Loss: 6.8600\nEpoch 21, Loss: 6.8498\nEpoch 22, Loss: 6.8430\nEpoch 23, Loss: 6.8395\nEpoch 24, Loss: 6.8386\nEpoch 25, Loss: 6.8396\nEpoch 26, Loss: 6.8414\nEpoch 27, Loss: 6.8432\nEpoch 28, Loss: 6.8441\nEpoch 29, Loss: 6.8438\nEpoch 30, Loss: 6.8421\nEpoch 31, Loss: 6.8393\nEpoch 32, Loss: 6.8357\nEpoch 33, Loss: 6.8318\nEpoch 34, Loss: 6.8279\nEpoch 35, Loss: 6.8242\nEpoch 36, Loss: 6.8206\nEpoch 37, Loss: 6.8172\nEpoch 38, Loss: 6.8138\nEpoch 39, Loss: 6.8102\nEpoch 40, Loss: 6.8066\n","output_type":"stream"}],"execution_count":43},{"cell_type":"code","source":"model_onehot_LSTM = LSTM_OneHot(vocab_size, 256)\ntrain_model(model_onehot, X_onehot, y_onehot, epochs=40)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-15T16:41:39.344331Z","iopub.execute_input":"2026-02-15T16:41:39.344585Z","iopub.status.idle":"2026-02-15T16:55:46.801205Z","shell.execute_reply.started":"2026-02-15T16:41:39.344567Z","shell.execute_reply":"2026-02-15T16:55:46.800447Z"}},"outputs":[{"name":"stdout","text":"Epoch 1, Loss: 6.8030\nEpoch 2, Loss: 6.8000\nEpoch 3, Loss: 6.7912\nEpoch 4, Loss: 6.7882\nEpoch 5, Loss: 6.7852\nEpoch 6, Loss: 6.7795\nEpoch 7, Loss: 6.7750\nEpoch 8, Loss: 6.7716\nEpoch 9, Loss: 6.7666\nEpoch 10, Loss: 6.7608\nEpoch 11, Loss: 6.7564\nEpoch 12, Loss: 6.7520\nEpoch 13, Loss: 6.7468\nEpoch 14, Loss: 6.7419\nEpoch 15, Loss: 6.7379\nEpoch 16, Loss: 6.7332\nEpoch 17, Loss: 6.7280\nEpoch 18, Loss: 6.7236\nEpoch 19, Loss: 6.7191\nEpoch 20, Loss: 6.7142\nEpoch 21, Loss: 6.7099\nEpoch 22, Loss: 6.7056\nEpoch 23, Loss: 6.7009\nEpoch 24, Loss: 6.6966\nEpoch 25, Loss: 6.6924\nEpoch 26, Loss: 6.6878\nEpoch 27, Loss: 6.6837\nEpoch 28, Loss: 6.6794\nEpoch 29, Loss: 6.6750\nEpoch 30, Loss: 6.6708\nEpoch 31, Loss: 6.6664\nEpoch 32, Loss: 6.6621\nEpoch 33, Loss: 6.6579\nEpoch 34, Loss: 6.6533\nEpoch 35, Loss: 6.6490\nEpoch 36, Loss: 6.6444\nEpoch 37, Loss: 6.6399\nEpoch 38, Loss: 6.6353\nEpoch 39, Loss: 6.6305\nEpoch 40, Loss: 6.6258\n","output_type":"stream"}],"execution_count":44},{"cell_type":"code","source":"def generate_text_onehot(model, start_words, num_words=20):\n    model.eval()\n    words = start_words.copy()\n\n    for _ in range(num_words):\n        seq = words[-seq_length:]\n        seq_vec = [one_hot_encode(word_to_idx[w], vocab_size) for w in seq]\n        seq_tensor = torch.stack(seq_vec).unsqueeze(0).to(device)\n\n        with torch.no_grad():\n            output = model(seq_tensor)\n            predicted = torch.argmax(output).item()\n\n        words.append(idx_to_word[predicted])\n\n    return \" \".join(words)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-15T16:55:46.802312Z","iopub.execute_input":"2026-02-15T16:55:46.802721Z","iopub.status.idle":"2026-02-15T16:55:46.807154Z","shell.execute_reply.started":"2026-02-15T16:55:46.802700Z","shell.execute_reply":"2026-02-15T16:55:46.806567Z"}},"outputs":[],"execution_count":45},{"cell_type":"code","source":"print(generate_text_onehot(model_onehot_RNN, tokens[:5]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-15T16:55:46.809059Z","iopub.execute_input":"2026-02-15T16:55:46.809255Z","iopub.status.idle":"2026-02-15T16:55:46.856021Z","shell.execute_reply.started":"2026-02-15T16:55:46.809239Z","shell.execute_reply":"2026-02-15T16:55:46.855404Z"}},"outputs":[{"name":"stdout","text":"text \"o my luve's like salt frigate under frigate by stud zones, prove run. leaf frigate zones, rais'd invalids, horn. owning stud rolls, salt square\n","output_type":"stream"}],"execution_count":46},{"cell_type":"code","source":"print(generate_text_onehot(model_onehot_LSTM, tokens[:5]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-15T16:55:46.857220Z","iopub.execute_input":"2026-02-15T16:55:46.857512Z","iopub.status.idle":"2026-02-15T16:55:46.969071Z","shell.execute_reply.started":"2026-02-15T16:55:46.857492Z","shell.execute_reply":"2026-02-15T16:55:46.968168Z"}},"outputs":[{"name":"stdout","text":"text \"o my luve's like people, uncurled gladdest i! nodding nodding prevent surly nodding ribs. nodding nodding ribs. nodding ribs. nodding nodding ribs. nodding ribs.\n","output_type":"stream"}],"execution_count":47},{"cell_type":"markdown","source":"Trainable Word Embeddings Approach","metadata":{}},{"cell_type":"markdown","source":"RNN with Embedding","metadata":{}},{"cell_type":"code","source":"class RNN_Embedding(nn.Module):\n    def __init__(self, vocab_size, embed_size, hidden_size):\n        super().__init__()\n        self.embedding = nn.Embedding(vocab_size, embed_size)\n        self.rnn = nn.RNN(embed_size, hidden_size, batch_first=True)\n        self.fc = nn.Linear(hidden_size, vocab_size)\n\n    def forward(self, x):\n        x = self.embedding(x)\n        out, _ = self.rnn(x)\n        out = self.fc(out[:, -1, :])\n        return out\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-15T16:55:46.970125Z","iopub.execute_input":"2026-02-15T16:55:46.970474Z","iopub.status.idle":"2026-02-15T16:55:46.975528Z","shell.execute_reply.started":"2026-02-15T16:55:46.970450Z","shell.execute_reply":"2026-02-15T16:55:46.974880Z"}},"outputs":[],"execution_count":48},{"cell_type":"markdown","source":"LSTM with Embedding","metadata":{}},{"cell_type":"code","source":"class LSTM_Embedding(nn.Module):\n    def __init__(self, vocab_size, embed_size, hidden_size):\n        super().__init__()\n        self.embedding = nn.Embedding(vocab_size, embed_size)\n        self.lstm = nn.LSTM(embed_size, hidden_size, batch_first=True)\n        self.fc = nn.Linear(hidden_size, vocab_size)\n\n    def forward(self, x):\n        x = self.embedding(x)\n        out, _ = self.lstm(x)\n        out = self.fc(out[:, -1, :])\n        return out\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-15T16:55:46.976488Z","iopub.execute_input":"2026-02-15T16:55:46.976782Z","iopub.status.idle":"2026-02-15T16:55:46.992706Z","shell.execute_reply.started":"2026-02-15T16:55:46.976763Z","shell.execute_reply":"2026-02-15T16:55:46.991823Z"}},"outputs":[],"execution_count":49},{"cell_type":"code","source":"X_embed = []\ny_embed = []\n\nfor seq, target in sequences:\n    seq_idx = [word_to_idx[w] for w in seq]\n    X_embed.append(seq_idx)\n    y_embed.append(word_to_idx[target])\n\nX_embed = torch.tensor(X_embed)\ny_embed = torch.tensor(y_embed)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-15T16:55:46.993525Z","iopub.execute_input":"2026-02-15T16:55:46.994443Z","iopub.status.idle":"2026-02-15T16:55:47.049563Z","shell.execute_reply.started":"2026-02-15T16:55:46.994402Z","shell.execute_reply":"2026-02-15T16:55:47.048758Z"}},"outputs":[],"execution_count":50},{"cell_type":"code","source":"X_embed = X_embed.to(device)\ny_embed = y_embed.to(device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-15T16:55:47.050667Z","iopub.execute_input":"2026-02-15T16:55:47.050952Z","iopub.status.idle":"2026-02-15T16:55:47.055208Z","shell.execute_reply.started":"2026-02-15T16:55:47.050923Z","shell.execute_reply":"2026-02-15T16:55:47.054289Z"}},"outputs":[],"execution_count":51},{"cell_type":"markdown","source":"Training","metadata":{}},{"cell_type":"code","source":"model_embed_RNN = RNN_Embedding(vocab_size, 100, 256)\ntrain_model(model_embed, X_embed, y_embed, epochs=40)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-15T16:55:47.056159Z","iopub.execute_input":"2026-02-15T16:55:47.056485Z","iopub.status.idle":"2026-02-15T16:57:40.892247Z","shell.execute_reply.started":"2026-02-15T16:55:47.056456Z","shell.execute_reply":"2026-02-15T16:57:40.891227Z"}},"outputs":[{"name":"stdout","text":"Epoch 1, Loss: 8.0428\nEpoch 2, Loss: 7.9350\nEpoch 3, Loss: 7.8227\nEpoch 4, Loss: 7.7083\nEpoch 5, Loss: 7.5947\nEpoch 6, Loss: 7.4847\nEpoch 7, Loss: 7.3813\nEpoch 8, Loss: 7.2869\nEpoch 9, Loss: 7.2035\nEpoch 10, Loss: 7.1320\nEpoch 11, Loss: 7.0722\nEpoch 12, Loss: 7.0232\nEpoch 13, Loss: 6.9837\nEpoch 14, Loss: 6.9519\nEpoch 15, Loss: 6.9263\nEpoch 16, Loss: 6.9052\nEpoch 17, Loss: 6.8874\nEpoch 18, Loss: 6.8717\nEpoch 19, Loss: 6.8574\nEpoch 20, Loss: 6.8438\nEpoch 21, Loss: 6.8305\nEpoch 22, Loss: 6.8172\nEpoch 23, Loss: 6.8039\nEpoch 24, Loss: 6.7907\nEpoch 25, Loss: 6.7781\nEpoch 26, Loss: 6.7660\nEpoch 27, Loss: 6.7546\nEpoch 28, Loss: 6.7438\nEpoch 29, Loss: 6.7336\nEpoch 30, Loss: 6.7238\nEpoch 31, Loss: 6.7142\nEpoch 32, Loss: 6.7047\nEpoch 33, Loss: 6.6952\nEpoch 34, Loss: 6.6856\nEpoch 35, Loss: 6.6758\nEpoch 36, Loss: 6.6657\nEpoch 37, Loss: 6.6555\nEpoch 38, Loss: 6.6450\nEpoch 39, Loss: 6.6344\nEpoch 40, Loss: 6.6237\n","output_type":"stream"}],"execution_count":52},{"cell_type":"code","source":"model_embed_LSTM = LSTM_Embedding(vocab_size, 100, 256)\ntrain_model(model_embed, X_embed, y_embed, epochs=40)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-15T16:57:40.893070Z","iopub.execute_input":"2026-02-15T16:57:40.893273Z","iopub.status.idle":"2026-02-15T16:59:35.978257Z","shell.execute_reply.started":"2026-02-15T16:57:40.893255Z","shell.execute_reply":"2026-02-15T16:59:35.977451Z"}},"outputs":[{"name":"stdout","text":"Epoch 1, Loss: 6.6130\nEpoch 2, Loss: 6.5938\nEpoch 3, Loss: 6.5787\nEpoch 4, Loss: 6.5644\nEpoch 5, Loss: 6.5496\nEpoch 6, Loss: 6.5343\nEpoch 7, Loss: 6.5189\nEpoch 8, Loss: 6.5036\nEpoch 9, Loss: 6.4882\nEpoch 10, Loss: 6.4725\nEpoch 11, Loss: 6.4567\nEpoch 12, Loss: 6.4407\nEpoch 13, Loss: 6.4246\nEpoch 14, Loss: 6.4083\nEpoch 15, Loss: 6.3918\nEpoch 16, Loss: 6.3753\nEpoch 17, Loss: 6.3586\nEpoch 18, Loss: 6.3418\nEpoch 19, Loss: 6.3248\nEpoch 20, Loss: 6.3077\nEpoch 21, Loss: 6.2904\nEpoch 22, Loss: 6.2729\nEpoch 23, Loss: 6.2553\nEpoch 24, Loss: 6.2374\nEpoch 25, Loss: 6.2193\nEpoch 26, Loss: 6.2010\nEpoch 27, Loss: 6.1825\nEpoch 28, Loss: 6.1637\nEpoch 29, Loss: 6.1448\nEpoch 30, Loss: 6.1256\nEpoch 31, Loss: 6.1063\nEpoch 32, Loss: 6.0867\nEpoch 33, Loss: 6.0668\nEpoch 34, Loss: 6.0467\nEpoch 35, Loss: 6.0263\nEpoch 36, Loss: 6.0057\nEpoch 37, Loss: 5.9848\nEpoch 38, Loss: 5.9637\nEpoch 39, Loss: 5.9422\nEpoch 40, Loss: 5.9206\n","output_type":"stream"}],"execution_count":53},{"cell_type":"code","source":"def generate_text_embed(model, start_words, num_words=20):\n    model.eval()\n    words = start_words.copy()\n\n    for _ in range(num_words):\n        seq = words[-seq_length:]\n        seq_idx = torch.tensor([[word_to_idx[w] for w in seq]]).to(device)\n\n        with torch.no_grad():\n            output = model(seq_idx)\n            predicted = torch.argmax(output).item()\n\n        words.append(idx_to_word[predicted])\n\n    return \" \".join(words)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-15T16:59:35.979112Z","iopub.execute_input":"2026-02-15T16:59:35.979356Z","iopub.status.idle":"2026-02-15T16:59:35.984633Z","shell.execute_reply.started":"2026-02-15T16:59:35.979332Z","shell.execute_reply":"2026-02-15T16:59:35.983806Z"}},"outputs":[],"execution_count":54},{"cell_type":"code","source":"print(generate_text_embed(model_embed_RNN, tokens[:5]))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-15T16:59:35.985650Z","iopub.execute_input":"2026-02-15T16:59:35.985909Z","iopub.status.idle":"2026-02-15T16:59:36.015877Z","shell.execute_reply.started":"2026-02-15T16:59:35.985888Z","shell.execute_reply":"2026-02-15T16:59:36.015270Z"}},"outputs":[{"name":"stdout","text":"text \"o my luve's like pushing man. coon-seekers slaughter'd brutish low rainbow as exhibition-gallery responses wreathed thither,) undisguised surpasses rivulet, man, offset seeming only tall\n","output_type":"stream"}],"execution_count":55},{"cell_type":"code","source":"print(generate_text_embed(model_embed_LSTM, tokens[:5]))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-15T16:59:36.016598Z","iopub.execute_input":"2026-02-15T16:59:36.016767Z","iopub.status.idle":"2026-02-15T16:59:36.039265Z","shell.execute_reply.started":"2026-02-15T16:59:36.016751Z","shell.execute_reply":"2026-02-15T16:59:36.038394Z"}},"outputs":[{"name":"stdout","text":"text \"o my luve's like squads yet—she decorum, such sorry poems? fares clothes shines sun,—the gladness, sun,—the sun,—the summits rous'd trifle purer lean canvas drape\n","output_type":"stream"}],"execution_count":56}]}